<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>生成式人工智能</title>
    <style>
        :root {
            --primary-color: #2E7D32;
            --secondary-color: #1B5E20;
            --background-color: #f5f5f5;
            --text-color: #333;
            --card-background: #ffffff;
            --hover-color: #E8F5E9;
            --code-background: #f8f9fa;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        header {
            text-align: center;
            margin-bottom: 3rem;
            padding: 2rem 0;
            background-color: var(--card-background);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        h1 {
            color: var(--primary-color);
            margin-bottom: 1rem;
            font-size: 2.5rem;
        }

        .subtitle {
            color: #666;
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .content {
            background-color: var(--card-background);
            border-radius: 8px;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        h2 {
            color: var(--primary-color);
            margin: 2rem 0 1rem;
            font-size: 1.8rem;
            border-bottom: 1px solid #eee;
            padding-bottom: 0.5rem;
        }

        h3 {
            color: var(--secondary-color);
            margin: 1.5rem 0 1rem;
            font-size: 1.4rem;
        }

        h4 {
            color: var(--secondary-color);
            margin: 1.2rem 0 0.8rem;
            font-size: 1.2rem;
        }

        p {
            margin-bottom: 1rem;
        }

        ul, ol {
            margin-bottom: 1rem;
            padding-left: 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        pre {
            background-color: var(--code-background);
            padding: 1rem;
            border-radius: 4px;
            overflow-x: auto;
            margin: 1rem 0;
        }

        code {
            font-family: Consolas, Monaco, 'Andale Mono', monospace;
        }

        .tip {
            background-color: var(--hover-color);
            border-left: 4px solid var(--primary-color);
            padding: 1rem;
            margin: 1rem 0;
        }

        .tip-title {
            font-weight: bold;
            margin-bottom: 0.5rem;
        }

        .warning {
            background-color: #FFF3E0;
            border-left: 4px solid #FF9800;
            padding: 1rem;
            margin: 1rem 0;
        }

        .warning-title {
            font-weight: bold;
            margin-bottom: 0.5rem;
            color: #E65100;
        }

        .table-of-contents {
            background-color: var(--code-background);
            padding: 1.5rem;
            border-radius: 4px;
            margin-bottom: 2rem;
        }

        .table-of-contents ul {
            list-style-type: none;
            padding-left: 0;
        }

        .table-of-contents li {
            margin-bottom: 0.5rem;
        }

        .table-of-contents a {
            color: var(--primary-color);
            text-decoration: none;
        }

        .table-of-contents a:hover {
            text-decoration: underline;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 0.75rem;
            text-align: left;
        }

        th {
            background-color: var(--hover-color);
            color: var(--primary-color);
        }

        tr:nth-child(even) {
            background-color: #f9f9f9;
        }

        .image-container {
            text-align: center;
            margin: 1.5rem 0;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .caption {
            font-style: italic;
            color: #666;
            margin-top: 0.5rem;
        }

        .reflection-questions {
            background-color: #E8F5E9;
            border-left: 4px solid #2E7D32;
            padding: 1rem;
            margin: 1rem 0 2rem 0;
            border-radius: 4px;
        }

        .back-to-home {
            display: inline-block;
            margin-top: 2rem;
            padding: 0.5rem 1rem;
            background-color: var(--primary-color);
            color: white;
            text-decoration: none;
            border-radius: 4px;
        }

        .back-to-home:hover {
            background-color: var(--secondary-color);
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>生成式人工智能</h1>
            <p class="subtitle">大型语言模型、扩散模型与多模态生成系统</p>
        </div>
    </header>

    <main class="container">
        <div class="table-of-contents">
            <h2>目录</h2>
            <ul>
                <li><a href="#introduction">1. 生成式AI简介与发展历程</a></li>
                <li><a href="#theory">2. 生成模型理论基础</a></li>
                <li><a href="#llm">3. 大型语言模型架构</a></li>
                <li><a href="#diffusion">4. 扩散模型与图像生成</a></li>
                <li><a href="#multimodal">5. 多模态生成系统</a></li>
                <li><a href="#prompt">6. 提示工程（Prompt Engineering）</a></li>
                <li><a href="#finetuning">7. 模型微调与定制化</a></li>
                <li><a href="#evaluation">8. 生成内容评估框架</a></li>
                <li><a href="#applications">9. 应用场景与商业化路径</a></li>
                <li><a href="#ethics">10. 伦理与安全考量</a></li>
            </ul>
        </div>

        <section id="introduction" class="content">
            <h2>1. 生成式AI简介与发展历程</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>生成式AI与传统AI技术有何本质区别？</li>
                    <li>生成式模型的主要应用领域有哪些？</li>
                    <li>您认为生成式AI的发展会如何改变人类创造性工作的方式？</li>
                    <li>在生成式AI的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>生成式人工智能(Generative AI)是指能够创建新内容的AI系统，包括文本、图像、音频、视频等多种形式。与传统的判别式AI（如分类器）不同，生成式AI的目标是创建与训练数据相似但又不完全相同的新内容，具有极强的创造性和适应性。</p>

            <h3>1.1 发展历程与里程碑</h3>
            <ul>
                <li><strong>早期生成模型（1950s-2000s）</strong>
                    <ul>
                        <li>马尔可夫链生成文本</li>
                        <li>基于规则的内容生成系统</li>
                        <li>简单的随机过程生成模型</li>
                    </ul>
                </li>
                <li><strong>深度生成模型兴起（2010-2017）</strong>
                    <ul>
                        <li>2014年：生成对抗网络（GAN）的提出</li>
                        <li>2015年：变分自编码器（VAE）成熟应用</li>
                        <li>2016-2017年：条件生成模型与风格迁移技术</li>
                    </ul>
                </li>
                <li><strong>大型语言模型时代（2017-2021）</strong>
                    <ul>
                        <li>2017年：Transformer架构提出</li>
                        <li>2018年：BERT预训练模型</li>
                        <li>2019年：GPT-2展示强大文本生成能力</li>
                        <li>2020年：GPT-3实现更复杂任务</li>
                    </ul>
                </li>
                <li><strong>多模态生成革命（2021-至今）</strong>
                    <ul>
                        <li>2021年：DALL-E、Stable Diffusion等图像生成模型</li>
                        <li>2022年：ChatGPT改变人机交互方式</li>
                        <li>2023年：GPT-4、Claude等多模态大模型</li>
                        <li>2023-2024年：文本到视频生成技术快速发展</li>
                    </ul>
                </li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/c7d3597ac3b7dac9e2f34ee633bf92d8.png" alt="生成式AI发展时间线">
                <p class="caption">图 1-1: 生成式AI主要技术路线与发展历程</p>
            </div>

            <h3>1.2 生成式AI的核心能力</h3>
            <ul>
                <li><strong>创造性内容生成</strong>：创作文本、设计图像、编写代码、作曲等</li>
                <li><strong>内容转换与翻译</strong>：跨模态转换（文本到图像、音频到文本等）</li>
                <li><strong>语义理解与上下文感知</strong>：理解复杂指令和环境上下文</li>
                <li><strong>个性化与定制</strong>：根据特定风格、需求调整输出</li>
                <li><strong>交互式协作</strong>：与人类进行迭代创作与改进</li>
            </ul>

            <h3>1.3 生成式AI的主要技术路线</h3>
            <p>当前生成式AI领域的主要技术路线包括：</p>
            
            <table>
                <thead>
                    <tr>
                        <th>技术路线</th>
                        <th>代表模型</th>
                        <th>主要优势</th>
                        <th>典型应用</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>自回归语言模型</td>
                        <td>GPT系列、LLaMA、Claude</td>
                        <td>长文本生成连贯、上下文理解能力强</td>
                        <td>对话系统、写作助手、代码生成</td>
                    </tr>
                    <tr>
                        <td>扩散模型</td>
                        <td>Stable Diffusion、DALL-E、Midjourney</td>
                        <td>高质量图像生成、精确控制</td>
                        <td>艺术创作、设计辅助、图像编辑</td>
                    </tr>
                    <tr>
                        <td>生成对抗网络</td>
                        <td>StyleGAN、CycleGAN</td>
                        <td>细节真实、风格迁移能力强</td>
                        <td>人脸生成、风格转换、图像增强</td>
                    </tr>
                    <tr>
                        <td>多模态融合模型</td>
                        <td>CLIP、Flamingo、GPT-4V</td>
                        <td>跨模态理解与生成</td>
                        <td>图文理解、视觉问答、多模态创作</td>
                    </tr>
                </tbody>
            </table>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>生成式AI正向更大规模、更多模态、更强控制性和更高效率四个方向发展。基础模型(Foundation Models)能力的提升和降本增效是当前研究的重点，而如何实现可靠的控制和提高内容的真实性与准确性是应用落地的关键挑战。</p>
            </div>
        </section>

        <section id="theory" class="content">
            <h2>2. 生成模型理论基础</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>概率生成模型和判别模型有何本质区别？</li>
                    <li>为什么生成模型通常比判别模型更难训练？</li>
                    <li>不同类型的生成模型各有什么数学基础？</li>
                    <li>生成模型的评价指标应该关注哪些方面？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>要深入理解和开发生成式AI，必须掌握其理论基础。生成模型的核心是学习数据分布，并能从这个分布中采样生成新的数据点。</p>

            <h3>2.1 概率生成模型基础</h3>
            <p>生成模型的基础是概率论，主要目标是学习数据的联合概率分布p(x)或条件分布p(x|y)：</p>
            <ul>
                <li><strong>显式密度模型</strong>：直接定义并优化数据的概率密度函数</li>
                <li><strong>隐变量模型</strong>：通过引入隐变量z，建模p(x|z)和p(z)</li>
                <li><strong>隐式密度模型</strong>：不直接定义概率分布，但能从中采样</li>
                <li><strong>能量模型</strong>：通过能量函数间接定义概率分布</li>
            </ul>

            <pre><code># 隐变量模型的基本思想示例 (VAE的概率视角)
# p(x) = ∫ p(x|z)p(z)dz

import torch
import torch.nn as nn

# 定义编码器网络（推断网络）q(z|x)
class Encoder(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super(Encoder, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        # 输出均值和方差
        self.fc_mu = nn.Linear(256, latent_dim)
        self.fc_var = nn.Linear(256, latent_dim)
    
    def forward(self, x):
        h = self.fc(x)
        mu = self.fc_mu(h)
        log_var = self.fc_var(h)
        return mu, log_var

# 定义解码器网络（生成网络）p(x|z)
class Decoder(nn.Module):
    def __init__(self, latent_dim, output_dim):
        super(Decoder, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, output_dim),
            nn.Sigmoid()  # 假设输出是图像像素值 [0,1]
        )
    
    def forward(self, z):
        return self.fc(z)</code></pre>

            <h3>2.2 主要生成模型框架对比</h3>
            <table>
                <thead>
                    <tr>
                        <th>模型类型</th>
                        <th>数学基础</th>
                        <th>优势</th>
                        <th>局限性</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>变分自编码器(VAE)</td>
                        <td>变分推断、最大似然估计</td>
                        <td>训练稳定、可解释的潜空间</td>
                        <td>生成样本细节较模糊</td>
                    </tr>
                    <tr>
                        <td>生成对抗网络(GAN)</td>
                        <td>博弈论、极大极小优化</td>
                        <td>高质量、逼真的生成结果</td>
                        <td>训练不稳定、模式崩溃</td>
                    </tr>
                    <tr>
                        <td>自回归模型</td>
                        <td>条件概率分解、最大似然</td>
                        <td>训练简单、适合序列数据</td>
                        <td>生成速度慢、长期依赖困难</td>
                    </tr>
                    <tr>
                        <td>扩散模型</td>
                        <td>非平衡热力学、得分匹配</td>
                        <td>高质量生成、训练稳定</td>
                        <td>采样速度慢、计算成本高</td>
                    </tr>
                    <tr>
                        <td>流模型(Flow)</td>
                        <td>可逆变换、变量代换公式</td>
                        <td>精确似然计算、快速采样</td>
                        <td>架构受限、计算复杂度高</td>
                    </tr>
                </tbody>
            </table>

            <h3>2.3 生成模型的训练原理</h3>
            <p>不同生成模型采用不同的训练目标和优化策略：</p>
            <ul>
                <li><strong>最大似然估计(MLE)</strong>：最大化观测数据的概率</li>
                <li><strong>变分下界(ELBO)优化</strong>：VAE的训练目标，近似最大似然</li>
                <li><strong>对抗训练</strong>：生成器与判别器的博弈优化</li>
                <li><strong>去噪训练</strong>：扩散模型中预测噪声或清晰信号</li>
                <li><strong>对比学习</strong>：最大化正样本对的相似度，最小化负样本对的相似度</li>
                <li><strong>自监督学习</strong>：从数据本身构造监督信号</li>
            </ul>


            <h3>2.4 评估生成模型的指标</h3>
            <p>评估生成模型的质量需要多维度指标：</p>
            <ul>
                <li><strong>样本质量</strong>：真实度、清晰度、细节保真度</li>
                <li><strong>样本多样性</strong>：覆盖数据分布的广度、避免模式崩溃</li>
                <li><strong>条件控制能力</strong>：对生成过程的精确控制程度</li>
                <li><strong>语义一致性</strong>：生成内容的语义合理性</li>
            </ul>

            <p>常用定量评估指标：</p>
            <ul>
                <li><strong>IS (Inception Score)</strong>：评估图像样本质量和多样性</li>
                <li><strong>FID (Fréchet Inception Distance)</strong>：测量生成分布与真实分布的相似度</li>
                <li><strong>BLEU, ROUGE, METEOR</strong>：评估文本生成质量</li>
                <li><strong>PPL (Perplexity)</strong>：语言模型流畅度评估</li>
                <li><strong>CLIP评分</strong>：文本-图像匹配程度</li>
            </ul>

            <div class="warning">
                <div class="warning-title">评估陷阱</div>
                <p>单一指标往往不能全面反映生成模型的性能。例如，一个只记忆训练集的模型可能有很高的样本质量但缺乏多样性；而过度强调多样性可能导致非真实样本。应综合多种指标和人类评估进行全面评价。</p>
            </div>

            <div class="tip">
                <div class="tip-title">理论与实践的桥梁</div>
                <p>尽管生成模型的理论框架各不相同，但它们共享许多设计思想和技术。掌握不同模型间的联系与区别，有助于灵活选择和组合适合特定任务的模型架构。例如，扩散模型可以被看作是带噪声的能量模型，而某些GAN变体可以从VAE的角度进行解释。</p>
            </div>
        </section>

        <section id="llm" class="content">
            <h2>3. 大型语言模型架构</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>为什么Transformer架构能在NLP任务中取得突破性进展？</li>
                    <li>大型语言模型的规模与性能之间是什么关系？</li>
                    <li>如何理解大语言模型的涌现能力（Emergent Abilities）？</li>
                    <li>大语言模型的训练过程中有哪些关键技术挑战？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>

            <h3>3.1 Transformer架构详解</h3>
            <p>Transformer是现代大型语言模型的基础架构，其核心特点包括：</p>
            <ul>
                <li><strong>自注意力机制</strong>：实现序列中任意位置的直接信息交互</li>
                <li><strong>多头注意力</strong>：从不同表示子空间捕获信息</li>
                <li><strong>位置编码</strong>：在无序的自注意力中注入位置信息</li>
                <li><strong>残差连接</strong>：缓解深层网络训练困难</li>
            </ul>

            <div class="image-container">
                <img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fsafe-img.xhscdn.com%2Fbw1%2Fa5055deb-0385-411d-b0bd-85b56dcf7e18%3FimageView2%2F2%2Fw%2F1080%2Fformat%2Fjpg&refer=http%3A%2F%2Fsafe-img.xhscdn.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1750748433&t=b0173b64ff25155853e3abe511c89f25" alt="Transformer架构图">
                <p class="caption">图 3-1: Transformer模型架构示意图</p>
            </div>

            <h3>3.2 大型语言模型的关键组件</h3>
            <table>
                <thead>
                    <tr>
                        <th>组件</th>
                        <th>功能</th>
                        <th>技术特点</th>
                        <th>优化方向</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>词嵌入层</td>
                        <td>将词转换为向量表示</td>
                        <td>上下文相关的动态嵌入</td>
                        <td>压缩词表、参数共享</td>
                    </tr>
                    <tr>
                        <td>注意力层</td>
                        <td>计算token间关联</td>
                        <td>多头并行计算</td>
                        <td>稀疏注意力、线性复杂度</td>
                    </tr>
                    <tr>
                        <td>前馈网络</td>
                        <td>非线性特征转换</td>
                        <td>位置级特征处理</td>
                        <td>激活函数优化</td>
                    </tr>
                    <tr>
                        <td>归一化层</td>
                        <td>稳定网络训练</td>
                        <td>层归一化</td>
                        <td>计算效率提升</td>
                    </tr>
                </tbody>
            </table>

            <h3>3.3 预训练与微调范式</h3>
            <p>现代大语言模型采用"预训练+微调"的训练范式：</p>
            <ul>
                <li><strong>预训练阶段</strong>
                    <ul>
                        <li>在海量文本上进行自监督学习</li>
                        <li>掌握语言的基础知识和模式</li>
                        <li>通常采用因果语言模型或掩码语言模型目标</li>
                    </ul>
                </li>
                <li><strong>微调阶段</strong>
                    <ul>
                        <li>在特定任务数据上进行有监督学习</li>
                        <li>指令微调（Instruction Tuning）</li>
                        <li>对齐微调（Alignment Tuning）</li>
                    </ul>
                </li>
            </ul>

            <h3>3.4 规模化训练技术</h3>
            <p>训练大型语言模型面临的主要技术挑战和解决方案：</p>
            <ul>
                <li><strong>分布式训练</strong>
                    <ul>
                        <li>数据并行：多GPU复制模型</li>
                        <li>模型并行：模型分片到多设备</li>
                        <li>流水线并行：层级划分计算</li>
                    </ul>
                </li>
                <li><strong>混合精度训练</strong>
                    <ul>
                        <li>FP16/BF16计算加速</li>
                        <li>动态损失缩放</li>
                        <li>梯度累积</li>
                    </ul>
                </li>
                <li><strong>内存优化</strong>
                    <ul>
                        <li>梯度检查点（Gradient Checkpointing）</li>
                        <li>ZeRO优化器</li>
                        <li>Offload策略</li>
                    </ul>
                </li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>大语言模型正朝着更高效的训练和推理方向发展。稀疏专家混合（MoE）、参数高效微调（PEFT）、量化压缩等技术使得在有限计算资源下也能获得强大的模型能力。同时，模型架构的改进（如Flash Attention、旋转位置编码等）也在不断提升性能。</p>
            </div>

            <div class="warning">
                <div class="warning-title">局限性</div>
                <p>尽管大语言模型表现出强大的能力，但仍存在推理不一致、幻觉、知识时效性等问题。理解这些局限性对于安全部署和应用至关重要。同时，模型的可解释性和知识更新机制也是重要的研究方向。</p>
            </div>
        </section>

        <section id="diffusion" class="content">
            <h2>4. 扩散模型与图像生成</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>扩散模型与传统生成模型有何不同？</li>
                    <li>扩散模型的主要应用场景有哪些？</li>
                    <li>您认为扩散模型的发展会如何改变图像生成领域？</li>
                    <li>在扩散模型的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>扩散模型(Diffusion Model)是一种基于概率的生成模型，通过逐步去噪过程来生成数据。与传统的生成模型不同，扩散模型在训练过程中需要逐步添加噪声，而在生成过程中则需要逐步去除噪声。</p>

            <h3>4.1 扩散模型的基本原理</h3>
            <p>扩散模型的核心思想是通过一个马尔可夫链逐步去噪声，最终生成高质量的数据。这个过程可以表示为：</p>
            <ul>
                <li><strong>前向过程</strong>：逐步添加噪声</li>
                <li><strong>反向过程</strong>：逐步去除噪声</li>
            </ul>

            <pre><code># 扩散模型的基本思想示例
# 前向过程：逐步添加噪声
# 反向过程：逐步去除噪声

import torch
import torch.nn as nn

# 定义前向过程的噪声函数
class ForwardProcess(nn.Module):
    def __init__(self, input_dim, noise_level):
        super(ForwardProcess, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.noise_level = noise_level
    
    def forward(self, x):
        h = self.fc(x)
        return h + self.noise_level * torch.randn_like(h)

# 定义反向过程的噪声函数
class ReverseProcess(nn.Module):
    def __init__(self, input_dim, noise_level):
        super(ReverseProcess, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, input_dim),
            nn.Sigmoid()  # 假设输出是图像像素值 [0,1]
        )
        self.noise_level = noise_level
    
    def forward(self, x):
        return self.fc(x) * self.noise_level</code></pre>

            <h3>4.2 扩散模型的训练与生成</h3>
            <p>扩散模型的训练和生成过程包括：</p>
            <ul>
                <li><strong>训练目标</strong>：最小化去噪过程的损失</li>
                <li><strong>生成过程</strong>：从噪声中逐步生成数据</li>
            </ul>

            <h3>4.3 扩散模型的应用场景</h3>
            <p>扩散模型在图像生成领域有广泛应用，包括：</p>
            <ul>
                <li>艺术创作</li>
                <li>设计辅助</li>
                <li>图像编辑</li>
                <li>视频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://miaobi-lite.bj.bcebos.com/miaobi/5mao/b%276LaF5YiG6L6o546HXzE3MzM5NDYwNjMuMzY3OTg1Mg%3D%3D%27/0.png" alt="扩散模型应用场景">
                <p class="caption">图 4-1: 扩散模型</p>
            </div>

            <h3>4.4 扩散模型的局限性与挑战</h3>
            <p>尽管扩散模型在图像生成领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>采样速度慢</strong>：由于去噪过程的逐步进行，采样速度相对较慢</li>
                <li><strong>计算成本高</strong>：训练和生成过程中需要大量的计算资源</li>
                <li><strong>模式崩溃</strong>：在训练过程中可能出现模式崩溃问题</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>扩散模型正朝着更高效的训练和采样方向发展。基于分数的生成模型、条件扩散模型等技术正在不断改进采样速度和计算效率。同时，扩散模型的可解释性和多样性生成能力也是重要的研究方向。</p>
            </div>
        </section>

        <section id="multimodal" class="content">
            <h2>5. 多模态生成系统</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>多模态生成系统与单模态生成系统有何不同？</li>
                    <li>多模态生成系统的应用场景有哪些？</li>
                    <li>您认为多模态生成系统的发展会如何改变内容创作领域？</li>
                    <li>在多模态生成系统的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>多模态生成系统(Multimodal Generative System)是指能够处理多种类型输入并生成多种类型输出的AI系统。与单模态生成系统不同，多模态生成系统能够同时处理文本、图像、音频等多种输入，并生成相应的输出。</p>

            <h3>5.1 多模态生成系统的基本原理</h3>
            <p>多模态生成系统的核心思想是通过一个统一的模型来处理多种类型的输入，并生成相应的输出。这个过程可以表示为：</p>
            <ul>
                <li><strong>多模态融合</strong>：将不同类型的输入融合到一个统一的表示空间中</li>
                <li><strong>统一生成</strong>：从统一的表示空间中生成输出</li>
            </ul>

            <pre><code># 多模态生成系统的基本思想示例
# 多模态融合：将不同类型的输入融合到一个统一的表示空间中
# 统一生成：从统一的表示空间中生成输出

import torch
import torch.nn as nn

# 定义多模态融合模型
class MultimodalModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(MultimodalModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        h = self.fc(x)
        return h

# 定义输出层
class OutputLayer(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(OutputLayer, self).__init__()
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        return self.fc(x)</code></pre>

            <h3>5.2 多模态生成系统的应用场景</h3>
            <p>多模态生成系统在内容创作领域有广泛应用，包括：</p>
            <ul>
                <li>文本到图像生成</li>
                <li>图像到文本生成</li>
                <li>文本到音频生成</li>
                <li>图像到音频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/multimodal_system_application.png" alt="多模态生成系统应用场景">
                <p class="caption">图 5-1: 多模态生成系统在内容创作中的应用场景</p>
            </div>

            <h3>5.3 多模态生成系统的局限性与挑战</h3>
            <p>尽管多模态生成系统在内容创作领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>模态间不一致性</strong>：不同模态之间的信息不一致性可能导致生成结果质量下降</li>
                <li><strong>计算成本高</strong>：多模态生成系统需要大量的计算资源</li>
                <li><strong>可解释性差</strong>：多模态生成系统的生成过程难以解释</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>多模态生成系统正朝着更高效的生成和解释方向发展。基于条件生成模型的多模态生成系统、基于对比学习的跨模态生成系统等技术正在不断改进生成质量和解释能力。同时，多模态生成系统的可扩展性和可解释性也是重要的研究方向。</p>
            </div>
        </section>

        <section id="prompt" class="content">
            <h2>6. 提示工程（Prompt Engineering）</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>提示工程与传统AI技术有何本质区别？</li>
                    <li>提示工程的主要应用领域有哪些？</li>
                    <li>您认为提示工程的发展会如何改变人类创造性工作的方式？</li>
                    <li>在提示工程的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>提示工程(Prompt Engineering)是指在AI系统中使用自然语言提示来引导生成过程的技术。与传统的AI技术不同，提示工程能够直接与AI系统进行交互，并根据用户的具体需求生成相应的内容。</p>

            <h3>6.1 提示工程的基本原理</h3>
            <p>提示工程的核心思想是通过自然语言提示来引导生成过程。这个过程可以表示为：</p>
            <ul>
                <li><strong>提示设计</strong>：根据具体需求设计自然语言提示</li>
                <li><strong>生成过程</strong>：根据提示生成相应的内容</li>
            </ul>

            <pre><code># 提示工程的基本思想示例
# 提示设计：根据具体需求设计自然语言提示
# 生成过程：根据提示生成相应的内容

import torch
import torch.nn as nn

# 定义提示工程模型
class PromptModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(PromptModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        h = self.fc(x)
        return h

# 定义输出层
class OutputLayer(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(OutputLayer, self).__init__()
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        return self.fc(x)</code></pre>

            <h3>6.2 提示工程的主要应用场景</h3>
            <p>提示工程在内容创作领域有广泛应用，包括：</p>
            <ul>
                <li>文本生成</li>
                <li>图像生成</li>
                <li>音频生成</li>
                <li>视频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/prompt_engineering_application.png" alt="提示工程应用场景">
                <p class="caption">图 6-1: 提示工程在内容创作中的应用场景</p>
            </div>

            <h3>6.3 提示工程的局限性与挑战</h3>
            <p>尽管提示工程在内容创作领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>可解释性差</strong>：提示工程的生成过程难以解释</li>
                <li><strong>计算成本高</strong>：提示工程需要大量的计算资源</li>
                <li><strong>模态间不一致性</strong>：不同模态之间的信息不一致性可能导致生成结果质量下降</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>提示工程正朝着更高效的生成和解释方向发展。基于条件生成模型的提示工程、基于对比学习的跨模态提示工程等技术正在不断改进生成质量和解释能力。同时，提示工程的可扩展性和可解释性也是重要的研究方向。</p>
            </div>
        </section>

        <section id="finetuning" class="content">
            <h2>7. 模型微调与定制化</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>模型微调与传统AI技术有何本质区别？</li>
                    <li>模型微调的主要应用领域有哪些？</li>
                    <li>您认为模型微调的发展会如何改变人类创造性工作的方式？</li>
                    <li>在模型微调的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>模型微调(Model Finetuning)是指在预训练模型的基础上，通过少量数据进行有监督学习，以适应特定任务的技术。与传统的AI技术不同，模型微调能够根据具体任务需求对模型进行定制化。</p>

            <h3>7.1 模型微调的基本原理</h3>
            <p>模型微调的核心思想是通过少量数据进行有监督学习，以适应特定任务。这个过程可以表示为：</p>
            <ul>
                <li><strong>微调目标</strong>：根据具体任务需求设计微调目标</li>
                <li><strong>微调过程</strong>：在预训练模型的基础上进行有监督学习</li>
            </ul>

            <pre><code># 模型微调的基本思想示例
# 微调目标：根据具体任务需求设计微调目标
# 微调过程：在预训练模型的基础上进行有监督学习

import torch
import torch.nn as nn

# 定义模型微调模型
class FinetuningModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(FinetuningModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        h = self.fc(x)
        return h

# 定义输出层
class OutputLayer(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(OutputLayer, self).__init__()
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        return self.fc(x)</code></pre>

            <h3>7.2 模型微调的主要应用场景</h3>
            <p>模型微调在内容创作领域有广泛应用，包括：</p>
            <ul>
                <li>文本生成</li>
                <li>图像生成</li>
                <li>音频生成</li>
                <li>视频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/model_finetuning_application.png" alt="模型微调应用场景">
                <p class="caption">图 7-1: 模型微调在内容创作中的应用场景</p>
            </div>

            <h3>7.3 模型微调的局限性与挑战</h3>
            <p>尽管模型微调在内容创作领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>可解释性差</strong>：模型微调的生成过程难以解释</li>
                <li><strong>计算成本高</strong>：模型微调需要大量的计算资源</li>
                <li><strong>模态间不一致性</strong>：不同模态之间的信息不一致性可能导致生成结果质量下降</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>模型微调正朝着更高效的生成和解释方向发展。基于条件生成模型的模型微调、基于对比学习的跨模态模型微调等技术正在不断改进生成质量和解释能力。同时，模型微调的可扩展性和可解释性也是重要的研究方向。</p>
            </div>
        </section>

        <section id="evaluation" class="content">
            <h2>8. 生成内容评估框架</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>生成内容评估框架与传统AI技术有何本质区别？</li>
                    <li>生成内容评估框架的主要应用领域有哪些？</li>
                    <li>您认为生成内容评估框架的发展会如何改变人类创造性工作的方式？</li>
                    <li>在生成内容评估框架的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>生成内容评估框架(Generative Content Evaluation Framework)是指用于评估生成内容质量的标准和方法。与传统的AI技术不同，生成内容评估框架能够对生成内容进行全面评估，并给出相应的评分和反馈。</p>

            <h3>8.1 生成内容评估框架的基本原理</h3>
            <p>生成内容评估框架的核心思想是通过一系列标准和方法来评估生成内容的质量。这个过程可以表示为：</p>
            <ul>
                <li><strong>评估标准</strong>：根据具体任务需求设计评估标准</li>
                <li><strong>评估方法</strong>：根据评估标准对生成内容进行评估</li>
            </ul>

            <pre><code># 生成内容评估框架的基本思想示例
# 评估标准：根据具体任务需求设计评估标准
# 评估方法：根据评估标准对生成内容进行评估

import torch
import torch.nn as nn

# 定义生成内容评估框架模型
class EvaluationModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(EvaluationModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        h = self.fc(x)
        return h

# 定义输出层
class OutputLayer(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(OutputLayer, self).__init__()
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        return self.fc(x)</code></pre>

            <h3>8.2 生成内容评估框架的主要应用场景</h3>
            <p>生成内容评估框架在内容创作领域有广泛应用，包括：</p>
            <ul>
                <li>文本生成</li>
                <li>图像生成</li>
                <li>音频生成</li>
                <li>视频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/generative_content_evaluation_framework_application.png" alt="生成内容评估框架应用场景">
                <p class="caption">图 8-1: 生成内容评估框架在内容创作中的应用场景</p>
            </div>

            <h3>8.3 生成内容评估框架的局限性与挑战</h3>
            <p>尽管生成内容评估框架在内容创作领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>可解释性差</strong>：生成内容评估框架的评估过程难以解释</li>
                <li><strong>计算成本高</strong>：生成内容评估框架需要大量的计算资源</li>
                <li><strong>模态间不一致性</strong>：不同模态之间的信息不一致性可能导致评估结果质量下降</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>生成内容评估框架正朝着更高效的评估和解释方向发展。基于条件生成模型的生成内容评估框架、基于对比学习的跨模态生成内容评估框架等技术正在不断改进评估质量和解释能力。同时，生成内容评估框架的可扩展性和可解释性也是重要的研究方向。</p>
            </div>
        </section>

        <section id="applications" class="content">
            <h2>9. 应用场景与商业化路径</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>应用场景与商业化路径与传统AI技术有何本质区别？</li>
                    <li>应用场景与商业化路径的主要应用领域有哪些？</li>
                    <li>您认为应用场景与商业化路径的发展会如何改变人类创造性工作的方式？</li>
                    <li>在应用场景与商业化路径的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>应用场景与商业化路径(Application Scenarios and Commercialization Path)是指AI系统在不同场景中的应用和商业化过程。与传统的AI技术不同，应用场景与商业化路径能够将AI系统应用于实际场景，并实现商业化。</p>

            <h3>9.1 应用场景与商业化路径的基本原理</h3>
            <p>应用场景与商业化路径的核心思想是通过一系列场景和方法来实现AI系统的商业化。这个过程可以表示为：</p>
            <ul>
                <li><strong>场景识别</strong>：根据具体需求识别应用场景</li>
                <li><strong>场景适配</strong>：根据应用场景对AI系统进行适配</li>
                <li><strong>场景实现</strong>：根据适配后的AI系统实现应用场景</li>
            </ul>

            <pre><code># 应用场景与商业化路径的基本思想示例
# 场景识别：根据具体需求识别应用场景
# 场景适配：根据应用场景对AI系统进行适配
# 场景实现：根据适配后的AI系统实现应用场景

import torch
import torch.nn as nn

# 定义应用场景与商业化路径模型
class ApplicationModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(ApplicationModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        h = self.fc(x)
        return h

# 定义输出层
class OutputLayer(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(OutputLayer, self).__init__()
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        return self.fc(x)</code></pre>

            <h3>9.2 应用场景与商业化路径的主要应用场景</h3>
            <p>应用场景与商业化路径在内容创作领域有广泛应用，包括：</p>
            <ul>
                <li>文本生成</li>
                <li>图像生成</li>
                <li>音频生成</li>
                <li>视频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/application_scenarios_and_commercialization_path_application.png" alt="应用场景与商业化路径应用场景">
                <p class="caption">图 9-1: 应用场景与商业化路径在内容创作中的应用场景</p>
            </div>

            <h3>9.3 应用场景与商业化路径的局限性与挑战</h3>
            <p>尽管应用场景与商业化路径在内容创作领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>可解释性差</strong>：应用场景与商业化路径的实现过程难以解释</li>
                <li><strong>计算成本高</strong>：应用场景与商业化路径需要大量的计算资源</li>
                <li><strong>模态间不一致性</strong>：不同模态之间的信息不一致性可能导致实现结果质量下降</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>应用场景与商业化路径正朝着更高效的实现和解释方向发展。基于条件生成模型的应用场景与商业化路径、基于对比学习的跨模态应用场景与商业化路径等技术正在不断改进实现质量和解释能力。同时，应用场景与商业化路径的可扩展性和可解释性也是重要的研究方向。</p>
            </div>
        </section>

        <section id="ethics" class="content">
            <h2>10. 伦理与安全考量</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>伦理与安全考量与传统AI技术有何本质区别？</li>
                    <li>伦理与安全考量主要应用领域有哪些？</li>
                    <li>您认为伦理与安全考量的发展会如何改变人类创造性工作的方式？</li>
                    <li>在伦理与安全考量的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>伦理与安全考量(Ethics and Security Consideration)是指在AI系统开发和应用过程中，考虑伦理和安全问题的技术和方法。与传统的AI技术不同，伦理与安全考量能够确保AI系统的安全性和可靠性。</p>

            <h3>10.1 伦理与安全考量的基本原理</h3>
            <p>伦理与安全考量的核心思想是通过一系列原则和方法来确保AI系统的安全性和可靠性。这个过程可以表示为：</p>
            <ul>
                <li><strong>伦理原则</strong>：根据伦理原则设计AI系统</li>
                <li><strong>安全方法</strong>：根据安全方法确保AI系统的安全性和可靠性</li>
            </ul>

            <pre><code># 伦理与安全考量的基本思想示例
# 伦理原则：根据伦理原则设计AI系统
# 安全方法：根据安全方法确保AI系统的安全性和可靠性

import torch
import torch.nn as nn

# 定义伦理与安全考量模型
class EthicsModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(EthicsModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        self.output_dim = output_dim
    
    def forward(self, x):
        h = self.fc(x)
        return h

# 定义输出层
class OutputLayer(nn.Module):
    def __init__(self, hidden_dim, output_dim):
        super(OutputLayer, self).__init__()
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        return self.fc(x)</code></pre>

            <h3>10.2 伦理与安全考量的主要应用场景</h3>
            <p>伦理与安全考量在内容创作领域有广泛应用，包括：</p>
            <ul>
                <li>文本生成</li>
                <li>图像生成</li>
                <li>音频生成</li>
                <li>视频生成</li>
            </ul>

            <div class="image-container">
                <img src="https://i-blog.csdnimg.cn/blog_migrate/ethics_and_security_consideration_application.png" alt="伦理与安全考量应用场景">
                <p class="caption">图 10-1: 伦理与安全考量在内容创作中的应用场景</p>
            </div>

            <h3>10.3 伦理与安全考量的局限性与挑战</h3>
            <p>尽管伦理与安全考量在内容创作领域表现出色，但仍面临一些局限性和挑战：</p>
            <ul>
                <li><strong>可解释性差</strong>：伦理与安全考量的实现过程难以解释</li>
                <li><strong>计算成本高</strong>：伦理与安全考量需要大量的计算资源</li>
                <li><strong>模态间不一致性</strong>：不同模态之间的信息不一致性可能导致实现结果质量下降</li>
            </ul>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>伦理与安全考量正朝着更高效的实现和解释方向发展。基于条件生成模型的伦理与安全考量、基于对比学习的跨模态伦理与安全考量等技术正在不断改进实现质量和解释能力。同时，伦理与安全考量的可扩展性和可解释性也是重要的研究方向。</p>
            </div>
        </section>

        <p>本教程的其他章节正在开发中，包括：</p>
        <ul>
            <li>大型语言模型架构</li>
            <li>扩散模型与图像生成</li>
            <li>多模态生成系统</li>
            <li>提示工程（Prompt Engineering）</li>
            <li>模型微调与定制化</li>
            <li>生成内容评估框架</li>
            <li>应用场景与商业化路径</li>
            <li>伦理与安全考量</li>
        </ul>

        <a href="../index.html" class="back-to-home">返回首页</a>
    </main>
</body>
</html> 