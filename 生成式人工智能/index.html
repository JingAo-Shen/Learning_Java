<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>生成式人工智能</title>
    <style>
        :root {
            --primary-color: #2E7D32;
            --secondary-color: #1B5E20;
            --background-color: #f5f5f5;
            --text-color: #333;
            --card-background: #ffffff;
            --hover-color: #E8F5E9;
            --code-background: #f8f9fa;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        header {
            text-align: center;
            margin-bottom: 3rem;
            padding: 2rem 0;
            background-color: var(--card-background);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        h1 {
            color: var(--primary-color);
            margin-bottom: 1rem;
            font-size: 2.5rem;
        }

        .subtitle {
            color: #666;
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .content {
            background-color: var(--card-background);
            border-radius: 8px;
            padding: 2rem;
            margin-bottom: 2rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        h2 {
            color: var(--primary-color);
            margin: 2rem 0 1rem;
            font-size: 1.8rem;
            border-bottom: 1px solid #eee;
            padding-bottom: 0.5rem;
        }

        h3 {
            color: var(--secondary-color);
            margin: 1.5rem 0 1rem;
            font-size: 1.4rem;
        }

        h4 {
            color: var(--secondary-color);
            margin: 1.2rem 0 0.8rem;
            font-size: 1.2rem;
        }

        p {
            margin-bottom: 1rem;
        }

        ul, ol {
            margin-bottom: 1rem;
            padding-left: 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        pre {
            background-color: var(--code-background);
            padding: 1rem;
            border-radius: 4px;
            overflow-x: auto;
            margin: 1rem 0;
        }

        code {
            font-family: Consolas, Monaco, 'Andale Mono', monospace;
        }

        .tip {
            background-color: var(--hover-color);
            border-left: 4px solid var(--primary-color);
            padding: 1rem;
            margin: 1rem 0;
        }

        .tip-title {
            font-weight: bold;
            margin-bottom: 0.5rem;
        }

        .warning {
            background-color: #FFF3E0;
            border-left: 4px solid #FF9800;
            padding: 1rem;
            margin: 1rem 0;
        }

        .warning-title {
            font-weight: bold;
            margin-bottom: 0.5rem;
            color: #E65100;
        }

        .table-of-contents {
            background-color: var(--code-background);
            padding: 1.5rem;
            border-radius: 4px;
            margin-bottom: 2rem;
        }

        .table-of-contents ul {
            list-style-type: none;
            padding-left: 0;
        }

        .table-of-contents li {
            margin-bottom: 0.5rem;
        }

        .table-of-contents a {
            color: var(--primary-color);
            text-decoration: none;
        }

        .table-of-contents a:hover {
            text-decoration: underline;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 0.75rem;
            text-align: left;
        }

        th {
            background-color: var(--hover-color);
            color: var(--primary-color);
        }

        tr:nth-child(even) {
            background-color: #f9f9f9;
        }

        .image-container {
            text-align: center;
            margin: 1.5rem 0;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .caption {
            font-style: italic;
            color: #666;
            margin-top: 0.5rem;
        }

        .reflection-questions {
            background-color: #E8F5E9;
            border-left: 4px solid #2E7D32;
            padding: 1rem;
            margin: 1rem 0 2rem 0;
            border-radius: 4px;
        }

        .back-to-home {
            display: inline-block;
            margin-top: 2rem;
            padding: 0.5rem 1rem;
            background-color: var(--primary-color);
            color: white;
            text-decoration: none;
            border-radius: 4px;
        }

        .back-to-home:hover {
            background-color: var(--secondary-color);
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>生成式人工智能</h1>
            <p class="subtitle">大型语言模型、扩散模型与多模态生成系统</p>
        </div>
    </header>

    <main class="container">
        <div class="table-of-contents">
            <h2>目录</h2>
            <ul>
                <li><a href="#introduction">1. 生成式AI简介与发展历程</a></li>
                <li><a href="#theory">2. 生成模型理论基础</a></li>
                <li><a href="#llm">3. 大型语言模型架构</a></li>
                <li><a href="#diffusion">4. 扩散模型与图像生成</a></li>
                <li><a href="#multimodal">5. 多模态生成系统</a></li>
                <li><a href="#prompt">6. 提示工程（Prompt Engineering）</a></li>
                <li><a href="#finetuning">7. 模型微调与定制化</a></li>
                <li><a href="#evaluation">8. 生成内容评估框架</a></li>
                <li><a href="#applications">9. 应用场景与商业化路径</a></li>
                <li><a href="#ethics">10. 伦理与安全考量</a></li>
            </ul>
        </div>

        <section id="introduction" class="content">
            <h2>1. 生成式AI简介与发展历程</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>生成式AI与传统AI技术有何本质区别？</li>
                    <li>生成式模型的主要应用领域有哪些？</li>
                    <li>您认为生成式AI的发展会如何改变人类创造性工作的方式？</li>
                    <li>在生成式AI的应用过程中，人类的角色是什么？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>生成式人工智能(Generative AI)是指能够创建新内容的AI系统，包括文本、图像、音频、视频等多种形式。与传统的判别式AI（如分类器）不同，生成式AI的目标是创建与训练数据相似但又不完全相同的新内容，具有极强的创造性和适应性。</p>

            <h3>1.1 发展历程与里程碑</h3>
            <ul>
                <li><strong>早期生成模型（1950s-2000s）</strong>
                    <ul>
                        <li>马尔可夫链生成文本</li>
                        <li>基于规则的内容生成系统</li>
                        <li>简单的随机过程生成模型</li>
                    </ul>
                </li>
                <li><strong>深度生成模型兴起（2010-2017）</strong>
                    <ul>
                        <li>2014年：生成对抗网络（GAN）的提出</li>
                        <li>2015年：变分自编码器（VAE）成熟应用</li>
                        <li>2016-2017年：条件生成模型与风格迁移技术</li>
                    </ul>
                </li>
                <li><strong>大型语言模型时代（2017-2021）</strong>
                    <ul>
                        <li>2017年：Transformer架构提出</li>
                        <li>2018年：BERT预训练模型</li>
                        <li>2019年：GPT-2展示强大文本生成能力</li>
                        <li>2020年：GPT-3实现更复杂任务</li>
                    </ul>
                </li>
                <li><strong>多模态生成革命（2021-至今）</strong>
                    <ul>
                        <li>2021年：DALL-E、Stable Diffusion等图像生成模型</li>
                        <li>2022年：ChatGPT改变人机交互方式</li>
                        <li>2023年：GPT-4、Claude等多模态大模型</li>
                        <li>2023-2024年：文本到视频生成技术快速发展</li>
                    </ul>
                </li>
            </ul>

            <div class="image-container">
                <img src="https://via.placeholder.com/800x400?text=生成式AI发展时间线" alt="生成式AI发展时间线">
                <p class="caption">图 1-1: 生成式AI主要技术路线与发展历程</p>
            </div>

            <h3>1.2 生成式AI的核心能力</h3>
            <ul>
                <li><strong>创造性内容生成</strong>：创作文本、设计图像、编写代码、作曲等</li>
                <li><strong>内容转换与翻译</strong>：跨模态转换（文本到图像、音频到文本等）</li>
                <li><strong>语义理解与上下文感知</strong>：理解复杂指令和环境上下文</li>
                <li><strong>个性化与定制</strong>：根据特定风格、需求调整输出</li>
                <li><strong>交互式协作</strong>：与人类进行迭代创作与改进</li>
            </ul>

            <h3>1.3 生成式AI的主要技术路线</h3>
            <p>当前生成式AI领域的主要技术路线包括：</p>
            
            <table>
                <thead>
                    <tr>
                        <th>技术路线</th>
                        <th>代表模型</th>
                        <th>主要优势</th>
                        <th>典型应用</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>自回归语言模型</td>
                        <td>GPT系列、LLaMA、Claude</td>
                        <td>长文本生成连贯、上下文理解能力强</td>
                        <td>对话系统、写作助手、代码生成</td>
                    </tr>
                    <tr>
                        <td>扩散模型</td>
                        <td>Stable Diffusion、DALL-E、Midjourney</td>
                        <td>高质量图像生成、精确控制</td>
                        <td>艺术创作、设计辅助、图像编辑</td>
                    </tr>
                    <tr>
                        <td>生成对抗网络</td>
                        <td>StyleGAN、CycleGAN</td>
                        <td>细节真实、风格迁移能力强</td>
                        <td>人脸生成、风格转换、图像增强</td>
                    </tr>
                    <tr>
                        <td>多模态融合模型</td>
                        <td>CLIP、Flamingo、GPT-4V</td>
                        <td>跨模态理解与生成</td>
                        <td>图文理解、视觉问答、多模态创作</td>
                    </tr>
                </tbody>
            </table>

            <div class="tip">
                <div class="tip-title">技术趋势</div>
                <p>生成式AI正向更大规模、更多模态、更强控制性和更高效率四个方向发展。基础模型(Foundation Models)能力的提升和降本增效是当前研究的重点，而如何实现可靠的控制和提高内容的真实性与准确性是应用落地的关键挑战。</p>
            </div>
        </section>

        <section id="theory" class="content">
            <h2>2. 生成模型理论基础</h2>
            
            <div class="reflection-questions">
                <h4 style="color: #2E7D32; margin-top: 0;">学习前思考</h4>
                <ol>
                    <li>概率生成模型和判别模型有何本质区别？</li>
                    <li>为什么生成模型通常比判别模型更难训练？</li>
                    <li>不同类型的生成模型各有什么数学基础？</li>
                    <li>生成模型的评价指标应该关注哪些方面？</li>
                </ol>
                <p style="font-style: italic; margin-bottom: 0;">在学习本章内容前，请先思考以上问题。带着问题学习，能够帮助您更好地理解和掌握知识点。</p>
            </div>
            
            <p>要深入理解和开发生成式AI，必须掌握其理论基础。生成模型的核心是学习数据分布，并能从这个分布中采样生成新的数据点。</p>

            <h3>2.1 概率生成模型基础</h3>
            <p>生成模型的基础是概率论，主要目标是学习数据的联合概率分布p(x)或条件分布p(x|y)：</p>
            <ul>
                <li><strong>显式密度模型</strong>：直接定义并优化数据的概率密度函数</li>
                <li><strong>隐变量模型</strong>：通过引入隐变量z，建模p(x|z)和p(z)</li>
                <li><strong>隐式密度模型</strong>：不直接定义概率分布，但能从中采样</li>
                <li><strong>能量模型</strong>：通过能量函数间接定义概率分布</li>
            </ul>

            <pre><code># 隐变量模型的基本思想示例 (VAE的概率视角)
# p(x) = ∫ p(x|z)p(z)dz

import torch
import torch.nn as nn

# 定义编码器网络（推断网络）q(z|x)
class Encoder(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super(Encoder, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU()
        )
        # 输出均值和方差
        self.fc_mu = nn.Linear(256, latent_dim)
        self.fc_var = nn.Linear(256, latent_dim)
    
    def forward(self, x):
        h = self.fc(x)
        mu = self.fc_mu(h)
        log_var = self.fc_var(h)
        return mu, log_var

# 定义解码器网络（生成网络）p(x|z)
class Decoder(nn.Module):
    def __init__(self, latent_dim, output_dim):
        super(Decoder, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, output_dim),
            nn.Sigmoid()  # 假设输出是图像像素值 [0,1]
        )
    
    def forward(self, z):
        return self.fc(z)</code></pre>

            <h3>2.2 主要生成模型框架对比</h3>
            <table>
                <thead>
                    <tr>
                        <th>模型类型</th>
                        <th>数学基础</th>
                        <th>优势</th>
                        <th>局限性</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>变分自编码器(VAE)</td>
                        <td>变分推断、最大似然估计</td>
                        <td>训练稳定、可解释的潜空间</td>
                        <td>生成样本细节较模糊</td>
                    </tr>
                    <tr>
                        <td>生成对抗网络(GAN)</td>
                        <td>博弈论、极大极小优化</td>
                        <td>高质量、逼真的生成结果</td>
                        <td>训练不稳定、模式崩溃</td>
                    </tr>
                    <tr>
                        <td>自回归模型</td>
                        <td>条件概率分解、最大似然</td>
                        <td>训练简单、适合序列数据</td>
                        <td>生成速度慢、长期依赖困难</td>
                    </tr>
                    <tr>
                        <td>扩散模型</td>
                        <td>非平衡热力学、得分匹配</td>
                        <td>高质量生成、训练稳定</td>
                        <td>采样速度慢、计算成本高</td>
                    </tr>
                    <tr>
                        <td>流模型(Flow)</td>
                        <td>可逆变换、变量代换公式</td>
                        <td>精确似然计算、快速采样</td>
                        <td>架构受限、计算复杂度高</td>
                    </tr>
                </tbody>
            </table>

            <h3>2.3 生成模型的训练原理</h3>
            <p>不同生成模型采用不同的训练目标和优化策略：</p>
            <ul>
                <li><strong>最大似然估计(MLE)</strong>：最大化观测数据的概率</li>
                <li><strong>变分下界(ELBO)优化</strong>：VAE的训练目标，近似最大似然</li>
                <li><strong>对抗训练</strong>：生成器与判别器的博弈优化</li>
                <li><strong>去噪训练</strong>：扩散模型中预测噪声或清晰信号</li>
                <li><strong>对比学习</strong>：最大化正样本对的相似度，最小化负样本对的相似度</li>
                <li><strong>自监督学习</strong>：从数据本身构造监督信号</li>
            </ul>

            <div class="image-container">
                <img src="https://via.placeholder.com/800x500?text=生成模型训练原理图" alt="生成模型训练原理图">
                <p class="caption">图 2-1: 不同生成模型的训练原理对比</p>
            </div>

            <h3>2.4 评估生成模型的指标</h3>
            <p>评估生成模型的质量需要多维度指标：</p>
            <ul>
                <li><strong>样本质量</strong>：真实度、清晰度、细节保真度</li>
                <li><strong>样本多样性</strong>：覆盖数据分布的广度、避免模式崩溃</li>
                <li><strong>条件控制能力</strong>：对生成过程的精确控制程度</li>
                <li><strong>语义一致性</strong>：生成内容的语义合理性</li>
            </ul>

            <p>常用定量评估指标：</p>
            <ul>
                <li><strong>IS (Inception Score)</strong>：评估图像样本质量和多样性</li>
                <li><strong>FID (Fréchet Inception Distance)</strong>：测量生成分布与真实分布的相似度</li>
                <li><strong>BLEU, ROUGE, METEOR</strong>：评估文本生成质量</li>
                <li><strong>PPL (Perplexity)</strong>：语言模型流畅度评估</li>
                <li><strong>CLIP评分</strong>：文本-图像匹配程度</li>
            </ul>

            <div class="warning">
                <div class="warning-title">评估陷阱</div>
                <p>单一指标往往不能全面反映生成模型的性能。例如，一个只记忆训练集的模型可能有很高的样本质量但缺乏多样性；而过度强调多样性可能导致非真实样本。应综合多种指标和人类评估进行全面评价。</p>
            </div>

            <div class="tip">
                <div class="tip-title">理论与实践的桥梁</div>
                <p>尽管生成模型的理论框架各不相同，但它们共享许多设计思想和技术。掌握不同模型间的联系与区别，有助于灵活选择和组合适合特定任务的模型架构。例如，扩散模型可以被看作是带噪声的能量模型，而某些GAN变体可以从VAE的角度进行解释。</p>
            </div>
        </section>

        <!-- 内容太长，展示前两个章节作为示例 -->
        <!-- 其他章节省略，实际应添加完整内容 -->

        <p>本教程的其他章节正在开发中，包括：</p>
        <ul>
            <li>大型语言模型架构</li>
            <li>扩散模型与图像生成</li>
            <li>多模态生成系统</li>
            <li>提示工程（Prompt Engineering）</li>
            <li>模型微调与定制化</li>
            <li>生成内容评估框架</li>
            <li>应用场景与商业化路径</li>
            <li>伦理与安全考量</li>
        </ul>

        <a href="../index.html" class="back-to-home">返回首页</a>
    </main>
</body>
</html> 